---
access: 'The files are available for download via HTTP. Link: http://traces.cs.umass.edu/index.php/Mmsys/Mmsys
  Direct link to the files: Link: http://skuld.cs.umass.edu/traces/mmsys/2013/markedhead/'
author: University of Oulu
categories:
- Video
citation: Use of the datasets in published work should be acknowledged by a full citation
  to the paper [SRH13] at the MMSys conference (Proceedings of ACM MMSys 13, February
  27 - March 1, 2013, Oslo, Norway).
contact_email: null
contact_name: ''
database: Consumer video dataset with marked head trajectories
excerpt: ''
external_link: http://traces.cs.umass.edu/index.php/Mmsys/Mmsys
hrc: ''
license: ''
method: ''
other: Head trajectories
partner: false
publicly_available: true
ratings: ''
references:
  SRH13: Jouni Sarvanko, Mika Rautiainen, Arto Heikkinen, Mika Ylianttila, Consumer
    video dataset with marked head trajectories, Proceedings of the 4th ACM Multimedia
    Systems Conferen (MMSys), Oslo, Norway, USA, February 27 - March 1, 2013.
resolution: ''
src: ''
subjective_scores: false
tags:
- Video
title: Consumer video dataset with marked head trajectories
total: ''
---

Content-based test video corpora usually builds on top of professional material or controlled settings. However, recent years have shown strong increase in user-generated content on the web. The increase in content volume creates challenges in accessibility and utility of the video content. In order to improve the utility of the user-generated videos, better automation for content-based descriptions are needed. Proper test sets are required to develop robust methods for content analysis. Detecting people from video is a common feature that is often seen in both in science and in commercial services. Unfortunately there is a lack of test data for person tracking from consumer videos. A novel video dataset accommodates this shortage. The dataset is done with two consumer-priced devices: a handheld camcorder and a mobile phone. Both devices were used to store material in indoor and outdoor settings with different attention levels from the people being filmed. The dataset comes with ground truth data that includes person head trajectories and other people marked in the background in MPEG-7-based metadata model. Description is given of this metadata model and an annotation tool used for creating the ground truth data is published. Experimental results are provided as a benchmark for all those who would like to use the dataset.