---
access: 'The files are available for download via HTTP. Link: https://purl.stanford.edu/zx935qw7203'
author: Stanford University
categories:
- Video
citation: Use of the datasets in published work should be acknowledged by a full citation
  to the authors' papers [ACC15] at the MMSys conference (Proceedings of ACM MMSys
  '15, Portland, Oregon, March 18-20, 2015).
contact_email: null
contact_name: "Andr\xE9 Filgueiras de Araujo (afaraujo@stanford.edu)"
database: 'Stanford I2V: A News Video Dataset for Query-by-Image Experiments'
excerpt: ''
external_link: http://blackhole1.stanford.edu/vidsearch/dataset/stanfordi2v.html
hrc: ''
license: ''
method: ''
other: Annotation for visual search
partner: false
publicly_available: true
ratings: ''
references:
  ACC15: 'A. Araujo, J. Chaves, D. Chen, R. Angst and B. Girod. Stanford I2V: A News
    Video Dataset for Query-by-Image Experiments, Proceedings of ACM MMSys ''15, Portland,
    Oregon, March 18-20, 2015.'
resolution: ''
src: ''
subjective_scores: false
tags:
- Video
title: 'Stanford I2V: A News Video Dataset for Query-by-Image Experiments'
total: ''
---

Reproducible research in the area of visual search depends on the availability of large annotated datasets. In this paper, we address the problem of querying a video database by images that might share some contents with one or more video clips. We present a new large dataset, called Stanford I2V. We have collected more than 3,800 hours of newscast videos and annotated more than 200 ground-truth queries. In the following, the dataset is described in detail, the collection methodology is outlined and retrieval performance for a benchmark algorithm is presented. These results may serve as a baseline for future research and provide an example of the intended use of the Stanford I2V dataset.